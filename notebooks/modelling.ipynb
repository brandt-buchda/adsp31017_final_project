{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../complete_data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"box_office\"] > 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins and numeric labels\n",
    "bins = [0, 1e6, 10e6, 50e6, 100e6, 200e6, 500e6, float('inf')]\n",
    "labels_dict = {\n",
    "    0: '0-1M',\n",
    "    1: '1-10M',\n",
    "    2: '10-50M',\n",
    "    3: '50-100M',\n",
    "    4: '100-200M',\n",
    "    5: '200M-500M',\n",
    "    6: '500M+'\n",
    "}\n",
    "\n",
    "# Assign numeric labels\n",
    "df['box_office_category'] = pd.cut(df['box_office'], bins=bins, labels=labels_dict.keys(), right=False).astype(int)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "X = df.drop(columns=['box_office_category', 'box_office', \"title\"])\n",
    "titles = df['title']\n",
    "y = df['box_office_category']\n",
    "\n",
    "# Split data while keeping it as a DataFrame\n",
    "X_train, X_test, y_train, y_test, titles_train, titles_test = train_test_split(\n",
    "    X, y, titles, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Now, X_test is still a DataFrame, so we can join title back\n",
    "df_test = pd.DataFrame(data=X_test, columns=X.columns)\n",
    "df_test[\"title\"] = titles_test.values  # Ensure title is assigned properly\n",
    "df_test[\"Actual\"] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter(y_train)\n",
    "scale_weights = {cls: sum(class_counts.values()) / count for cls, count in class_counts.items()}\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(labels_dict),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    scale_pos_weight=[scale_weights[i] for i in sorted(scale_weights.keys())]\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "df_test[\"Predicted\"] = y_pred  # Ensure y_pred is also in the correct shape\n",
    "\n",
    "# Compute accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=labels_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert numeric categories back to readable labels\n",
    "y_test_labels = [labels_dict[label] for label in y_test]\n",
    "y_pred_labels = [labels_dict[label] for label in y_pred]\n",
    "\n",
    "# Create a crosstab\n",
    "crosstab_df = pd.crosstab(pd.Series(y_test_labels, name=\"Actual\"),\n",
    "                          pd.Series(y_pred_labels, name=\"Predicted\"),\n",
    "                          margins=True)  # Adds row/column totals\n",
    "\n",
    "print(crosstab_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Error_Size\"] = abs(df_test[\"Actual\"] - df_test[\"Predicted\"])\n",
    "\n",
    "df_test = df_test.sort_values(by=\"Error_Size\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Actual\"] = df_test[\"Actual\"].map(labels_dict)\n",
    "df_test[\"Predicted\"] = df_test[\"Predicted\"].map(labels_dict)\n",
    "\n",
    "df_test[\"box_office\"] = df.loc[df_test.index, \"box_office\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_df = df_test[df_test[\"Actual\"] != df_test[\"Predicted\"]]\n",
    "\n",
    "# Save to CSV\n",
    "misclassified_df[[\"title\", \"box_office\", \"Actual\", \"Predicted\"]].to_csv(\"misclassified_movies.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for easy sorting\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "n = 10\n",
    "\n",
    "# Sort by importance and get top n features\n",
    "top_n_features = importance_df.sort_values(by='Importance', ascending=False).head(n)\n",
    "\n",
    "# Plot top n features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_n_features['Feature'], top_n_features['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title(f'Top {n} Feature Importances')\n",
    "plt.gca().invert_yaxis()  # Optional: To have the most important features at the top\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your original DataFrame with box_office as the target\n",
    "X = df.drop(columns=[\"box_office\", \"title\", \"box_office_category\"])\n",
    "y = df[\"box_office\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a Bagging Regressor with DecisionTree as the base estimator\n",
    "bagging_model = BaggingRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500, 1000],  # Different values for n_estimators to try\n",
    "    'max_samples': [0.5, 0.8, 1.0],          # Fraction of samples to train each estimator on\n",
    "    'max_features': [0.5, 0.8, 1.0]          # Fraction of features to train each estimator on\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(bagging_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best models from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best models\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the train-test split\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Scaled RMSE (scaled by the range of the target variable)\n",
    "y_range = y.max() - y.min()\n",
    "scaled_rmse = rmse_test / y_range\n",
    "\n",
    "print(\"Train-test split evaluation metrics:\")\n",
    "print(f\"RMSE: {rmse_test:.4f}\")\n",
    "print(f\"Scaled RMSE: {scaled_rmse:.4f}\")\n",
    "print(f\"MAPE: {mape_test:.4%}\")\n",
    "print(f\"R^2 Score: {r2_test:.4f}\")\n",
    "\n",
    "# Cross-validation (on the best models)\n",
    "cv_results = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Convert negative MSE to positive and compute RMSE for cross-validation\n",
    "mse_cv = -cv_results\n",
    "rmse_cv = np.sqrt(mse_cv)\n",
    "\n",
    "# Calculate RÂ² and MAPE for cross-validation\n",
    "cv_r2_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "cv_mape_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1)\n",
    "\n",
    "# Convert negative MAPE to positive\n",
    "cv_mape_scores = -cv_mape_scores\n",
    "\n",
    "# Print cross-validation evaluation metrics\n",
    "print(\"\\nCross-validation evaluation metrics:\")\n",
    "print(f\"Cross-validated RMSE: {rmse_cv.mean():.4f} Â± {rmse_cv.std():.4f}\")\n",
    "print(f\"Cross-validated RÂ²: {cv_r2_scores.mean():.4f} Â± {cv_r2_scores.std():.4f}\")\n",
    "print(f\"Cross-validated MAPE: {cv_mape_scores.mean():.4%} Â± {cv_mape_scores.std():.4%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
