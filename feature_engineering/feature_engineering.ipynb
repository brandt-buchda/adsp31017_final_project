{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cpi\n",
    "from fredapi import Fred\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "from utilites import column_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_df_with_emotion_scores.csv\", low_memory=False)\n",
    "display(column_stats(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_merge = pd.read_csv(\"final_dataset_cam.csv\")\n",
    "print(df_to_merge.columns.to_list())\n",
    "display(column_stats(df_to_merge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_titles(df, column=\"title\"):\n",
    "    df[column] = df[column].str.lower().str.strip()\n",
    "    df[column] = df[column].apply(lambda x: ' '.join(re.sub(r'[^a-z0-9\\s]', '', x).split()) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "df_to_merge = standardize_titles(df_to_merge)\n",
    "\n",
    "# Merge only the id_x column from df_merged into df\n",
    "df = df.merge(df_to_merge[['title', 'Team_Review_Score_sum', 'Team_Review_Score_mean', 'Team_Audience_Score_Mean', 'Team_Tomato_Meter_Mean', 'Team_Num_reviews', 'Cast_Review_Score_sum', 'Cast_Review_Score_mean', 'Cast_Audience_Score_Mean', 'Cast_Tomato_Meter_Mean', 'Cast_Num_reviews', 'Cast_creationDate', 'Cast_audienceScore', 'Cast_tomatoMeter', 'Cast_Cluster_Label', 'Team_creationDate', 'Team_audienceScore', 'Team_tomatoMeter', 'Team_Cluster Label']], left_on='title', right_on='title', how='left')\n",
    "\n",
    "# Display column stats\n",
    "display(column_stats(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(column_stats(df_to_merge))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Create CPI Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fred = Fred(api_key='<YOUR-API-KEY-HERE>')\n",
    "#\n",
    "# cpi_series = fred.get_series('CPIAUCSL', observation_start='1977-01-01', observation_end='2024-12-31')\n",
    "#\n",
    "# cpi_df = pd.DataFrame(cpi_series)\n",
    "# cpi_df.columns = ['CPI']\n",
    "#\n",
    "# cpi_df.to_csv('external/cpi_data.csv')\n",
    "\n",
    "cpi_df = pd.read_csv(\"external/cpi_data.csv\", names=[\"date\", \"cpi\"], skiprows=1)\n",
    "cpi_df[\"date\"] = pd.to_datetime(cpi_df[\"date\"])\n",
    "cpi_df.set_index(\"date\", inplace=True)\n",
    "cpi_yearly_df = cpi_df.resample(\"YE\").mean()\n",
    "cpi_yearly_df[\"year\"] = cpi_yearly_df.index.year\n",
    "cpi_yearly_df.set_index(\"year\", inplace=True)\n",
    "display(cpi_yearly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(cpi_yearly_df, left_on=\"release_year\", right_index=True, how=\"left\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Create Box Office Gross Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office_gross_df = pd.read_csv(\"external/box_office_revenue.csv\", low_memory=False)\n",
    "box_office_gross_df.set_index(\"year\", inplace=True)\n",
    "display(box_office_gross_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(box_office_gross_df, left_on=\"release_year\", right_index=True, how=\"left\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Create Box Office Adjusted Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_cpi = cpi_yearly_df[\"cpi\"].iloc[-1]\n",
    "latest_gross = df[\"box_office_gross\"].iloc[-1]\n",
    "\n",
    "df[\"box_office_adjusted\"] = (\n",
    "    df[\"box_office\"]\n",
    "    * (latest_cpi / df[\"cpi\"])\n",
    "    * (latest_gross / df[\"box_office_gross\"])\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Encode and Impute Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"rating\"].unique())\n",
    "\n",
    "def encode_rating(rating):\n",
    "    rating_map = {\n",
    "        np.nan: 0,\n",
    "        \"pg\": 1,\n",
    "        \"tvpg\": 2,\n",
    "        \"pg-13\": 3,\n",
    "        \"nc-17\": 4,\n",
    "        \"tvma\": 5,\n",
    "        \"r\": 6\n",
    "    }\n",
    "    return rating_map[rating]\n",
    "\n",
    "df[\"rating\"] = df[\"rating\"].apply(lambda x: encode_rating(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Encode Distributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def process_comma_separated_column(df, column_name, top_n=10):\n",
    "    # Step 1: Extract valid values and count occurrences\n",
    "    all_values = []\n",
    "    for values in df[column_name]:\n",
    "        if isinstance(values, str):  # Ensure only strings are processed\n",
    "            all_values.extend([value.strip() for value in values.split(',')])\n",
    "\n",
    "    value_counts = Counter(all_values)\n",
    "\n",
    "    # Step 2: Get the `top_n` most frequent values\n",
    "    top_values = {v for v, _ in value_counts.most_common(top_n)}\n",
    "\n",
    "    # Step 3: Create boolean columns for the top values\n",
    "    for value in top_values:\n",
    "        df[value] = df[column_name].apply(lambda x: isinstance(x, str) and any(v.strip() == value for v in x.split(',')))\n",
    "\n",
    "    # Step 4: Drop the original column\n",
    "    df.drop(columns=[column_name], inplace=True)\n",
    "\n",
    "process_comma_separated_column(df, 'distributor', top_n=10)\n",
    "process_comma_separated_column(df, 'sound_mix', top_n=5)\n",
    "process_comma_separated_column(df, 'rating_contents', top_n=10)\n",
    "process_comma_separated_column(df, 'genre', top_n=10)\n",
    "process_comma_separated_column(df, 'Cast_Cluster_Label', top_n=10)\n",
    "process_comma_separated_column(df, 'Team_Cluster Label', top_n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Encode Belongs to Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_in_collection\"] = df[\"belongs_to_collection\"].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_eval(value):\n",
    "    \"\"\"Safely evaluate a string representation of a dictionary.\"\"\"\n",
    "    if pd.isna(value):  # Handle NaN values\n",
    "        return None\n",
    "    if isinstance(value, dict):  # Already a dictionary, no need to parse\n",
    "        return value\n",
    "    if not isinstance(value, str):  # If it's not a string, return None\n",
    "        return None\n",
    "    try:\n",
    "        parsed_value = ast.literal_eval(value)\n",
    "        if isinstance(parsed_value, dict):  # Ensure it's a dictionary\n",
    "            return parsed_value\n",
    "    except (ValueError, SyntaxError):  # Catch any parsing errors\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "# Convert the column from string to dictionary safely\n",
    "df[\"belongs_to_collection\"] = df[\"belongs_to_collection\"].apply(safe_eval)\n",
    "\n",
    "# Extract collection ID\n",
    "df[\"collection_id\"] = df[\"belongs_to_collection\"].apply(lambda x: x[\"id\"] if isinstance(x, dict) else None)\n",
    "\n",
    "# Compute the average box office per collection\n",
    "collection_avg_box_office = df.groupby(\"collection_id\")[\"box_office\"].mean()\n",
    "\n",
    "# Map the computed averages back to the DataFrame\n",
    "df[\"collection_box_office_average\"] = df[\"collection_id\"].map(collection_avg_box_office)\n",
    "\n",
    "# Fill NaN values (movies not in a collection) with 0\n",
    "df[\"collection_box_office_average\"] = df[\"collection_box_office_average\"].fillna(0)\n",
    "df.drop(columns=[\"belongs_to_collection\"], inplace=True)\n",
    "\n",
    "df[\"collection_id\"] = df[\"collection_id\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"title\", \"director\", \"writer\", \"Dominant_Emotion\", \"id_x\", \"Cast_creationDate\", \"Team_creationDate\", \"cast\", \"wiki_page\", \"plot\", \"id\", \"release_year\", \"audience_score\", \"tomato_meter\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"budget\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "display(column_stats(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../complete_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "X = df.drop(columns=[\"box_office\", \"box_office_adjusted\"])  # Features\n",
    "y = np.log1p(df[\"box_office_adjusted\"])  # Log-transform target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define XGBoost model\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"max_depth\": 16,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 1000,\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and reverse log-transform\n",
    "y_pred = np.expm1(model.predict(X_test))\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mean_squared_error(np.expm1(y_test), y_pred))\n",
    "\n",
    "# MAPE (can still be unstable)\n",
    "mape = mean_absolute_percentage_error(np.expm1(y_test), y_pred)\n",
    "\n",
    "# SMAPE Calculation\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "smape_score = smape(np.expm1(y_test), y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAPE: {mape:.4%}\")\n",
    "print(f\"SMAPE: {smape_score:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
